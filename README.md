# Proyecto 5C â€“ Big Data (Yellow Taxi NYC)
AnÃ¡lisis comparativo de propinas ("tips") de los Yellow Taxis de Nueva York usando una arquitectura moderna basada en AWS S3, AWS Lambda, Supabase y Jupyter Notebook.

Este proyecto forma parte del curso de Datos Masivos y tiene como objetivo construir un flujo de datos real, procesar datasets autÃ©nticos y generar visualizaciones y conclusiones basadas en un caso prÃ¡ctico.

---

# ğŸš€ Arquitectura General

El flujo de datos implementado en este proyecto es:

Dataset (CSV)
â†’ AWS S3 (Raw Layer)
â†’ AWS Lambda (Procesamiento automÃ¡tico)
â†’ Supabase (Base de Datos PostgreSQL)
â†’ Jupyter Notebook (AnÃ¡lisis y VisualizaciÃ³n)


### **Servicios utilizados**

| Servicio        | Rol en el proyecto |
|-----------------|--------------------|
| **AWS S3**      | Almacena los datasets crudos (enero y febrero 2016). |
| **AWS Lambda**  | Procesa automÃ¡ticamente los archivos al subirse a S3. |
| **Supabase**    | ActÃºa como base de datos y API REST para guardar las mÃ©tricas procesadas. |
| **Jupyter**     | Herramienta principal para anÃ¡lisis, grÃ¡ficos y conclusiones del equipo. |

---

# ğŸ“ Estructura del Repositorio
â”‚
â”œâ”€â”€ docs/ # DocumentaciÃ³n del proyecto
â”‚ â”œâ”€â”€ informe_proyecto.md
â”‚ â””â”€â”€ diagramas_arquitectura.png
â”‚
â”œâ”€â”€ infra/ # Infraestructura y cÃ³digo backend
â”‚ â””â”€â”€ lambda_processors/ # CÃ³digo para la funciÃ³n AWS Lambda
â”‚ â”œâ”€â”€ handler.py
â”‚ â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ notebooks/ # Jupyter notebooks del anÃ¡lisis
â”‚ â”œâ”€â”€ .gitkeep
â”‚ â””â”€â”€ exploracion_inicial.ipynb
â”‚
â”œâ”€â”€ .env.example # Plantilla (segura) del archivo de configuraciÃ³n
â”œâ”€â”€ .gitignore # Archivos que deben ser ignorados por Git
â”‚
â””â”€â”€ README.md # Este archivo


---

# ğŸ‘¥ ColaboraciÃ³n en Equipo

Todos los miembros del equipo trabajan sobre el mismo repositorio, siguiendo estas reglas:

### **Cada miembro tendrÃ¡:**
- Su propio **usuario IAM** dentro de la cuenta AWS del proyecto.
- Su propio **Access Key + Secret Key**.
- Acceso de lectura/escritura al bucket S3 asignado.
- Acceso como colaborador al repositorio de GitHub.
- La misma URL y **anon key** de Supabase.

### **NingÃºn miembro comparte:**
âŒ Access Keys  
âŒ Secret Keys  
âŒ service_role key de Supabase  
âŒ `.env` real  

---

# âš™ï¸ InstalaciÃ³n y ConfiguraciÃ³n del Entorno (GuÃ­a para el Equipo)

## 1ï¸âƒ£ Clonar el repositorio

bash
git clone https://github.com/Gardner24/proyecto5c-datosmasivos.git
cd proyecto5c-datosmasivos
3ï¸âƒ£ Configurar el archivo .env

Copiar la plantilla:

copy .env.example .env


Editar:

notepad .env


Agregar valores:

AWS_ACCESS_KEY_ID=TU_KEY_PERSONAL
AWS_SECRET_ACCESS_KEY=TU_SECRET_PERSONAL
AWS_REGION=us-east-1

SUPABASE_URL=https://TU_PROYECTO.supabase.co
SUPABASE_KEY=TU_ANON_KEY


âš ï¸ El archivo .env nunca se sube a GitHub.
EstÃ¡ protegido por .gitignore. Cada miembro tiene su propio archivo local.

ğŸ§ª VerificaciÃ³n del Entorno

4ï¸âƒ£ Probar carga del .env (seguro para screenshot)
from dotenv import load_dotenv
import os

load_dotenv()

print("AWS_ACCESS_KEY_ID:", os.getenv("AWS_ACCESS_KEY_ID")[:4] + "****")
print("SUPABASE_URL:", os.getenv("SUPABASE_URL"))
print("SUPABASE_KEY:", os.getenv("SUPABASE_KEY")[:6] + "****")

5ï¸âƒ£ Probar conexiÃ³n a AWS S3
import boto3

s3 = boto3.client("s3")
resp = s3.list_buckets()

print("ConexiÃ³n S3 OK")
print("Buckets:")
for b in resp["Buckets"]:
    print(" -", b["Name"])

    from supabase import create_client
import os

url = os.getenv("SUPABASE_URL")
key = os.getenv("SUPABASE_KEY")

supabase = create_client(url, key)

print("ConexiÃ³n Supabase OK:", supabase is not None)


